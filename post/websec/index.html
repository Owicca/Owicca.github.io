<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=author content="OWicca"><meta name=generator content="Hugo 0.102.3"><title>Web application security — Down the wabbit's hole</title><meta name=description content><link rel=canonical href=https://www.dinudev.com/post/websec/><link href rel=alternate type=application/rss+xml title="Down the wabbit's hole"><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Source+Code+Pro|Arvo:400,700"><link rel=stylesheet href=https://www.dinudev.com/css/highlight.css><link rel=stylesheet href=https://www.dinudev.com/css/paperback.css><link rel=stylesheet href=https://www.dinudev.com/css/main.css></head><body><div class=container><header><h1>Web application security</h1><nav class=site-nav><a href=/>Home</a>
<a href=/post/>All posts</a>
<a href=/journey/>The journey</a>
<a href=/paper/>Papers</a></nav></header><article><h3 id=security-formalism-failure-reasons>Security formalism failure reasons:</h3><ul><li>to many different parties act on the same system,
and the changes are too many and too quick for a static structure to be described</li><li>IF everybody stops and decides on a common structure,
that does not mean the structure can be translated in a set of computable constrains</li><li>as of yet, there is not an way to prove, through static analysis,
that an application will behave the way it was meant to behave, in complex, real-world scenarios;
Turing also proved that there can be no algorithm that can show the outcome of another algorithm</li></ul><h3 id=risk-management>Risk management:</h3><ul><li>in interconnected systems,
even the most benign endpoint can be used to enter a network,
and escalate from there, or pivot horizontally;
a IoT door lock can be the entrypoint for a ransomeware</li><li>it is hard to account for potential lawsuits,
users loss of confidence in the brand</li><li>its a high chance that self-reported data is incomplete,
or breaches are unreported</li><li>the attack surface is large and any one part can be attacked succesfuly,
althou some parts are targeted more(statistically speaking),
no one part is more important than the rest</li></ul><h3 id=things-that-work>Things that work:</h3><ul><li>learn from(preferably other people&rsquo;s) mistakes</li><li>develop tools to detect and fix problems</li><li>presume everything is compromised</li></ul><h3 id=pragmatic-methods>Pragmatic methods:</h3><ul><li>what is the exposed surface of the modern browsers?</li><li>what are the tools? How to use the tools safely?</li><li>what parts of the web are commonly misunderstood?</li><li>how to control collateral damage?</li></ul><h6 id=desktop-apps-vs-web-apps>desktop apps vs web apps:</h6><ul><li>on the desktop, the os takes care of scheduling,
IO, access control, and separates domains quite clearly</li><li>on the desktop, there is a clear separation between data and code</li><li>on the web the separation between data and code is in the best case, partial,
bolted on after the fact, with superficial and overly complex sets of rules
that ultimately do not help</li><li>on the web, processing is done single-thread, no equivalent to CPU preemption,
no robust memory protection, no multi-tasking(asyncronous tasks can be run on secondary event loop):<ul><li>isn&rsquo;t multi-tasking a broader term that encompases subclasses like asyncronicity and concurency !?!?</li></ul></li><li>on the web is very hard(sometimes) to even draw a line where an application ends and another starts</li></ul><h3 id=xss-types>XSS types:</h3><ol start=0><li>DOM-based: a link to a page that runs a js that accesses a vulnerable file on the disk;
the vulnerable file will run with the same privileges as the browser</li><li>reflected: a page is using user input right away to generate another page;
think of a search bar in a search engine that displays on results page
the query entered</li><li>stored: user input is not filtered and it is stored;
everytime it is displayed back, xss happens</li></ol><h3 id=xss-mitigation>XSS mitigation:</h3><ul><li>filter every input</li><li>escape every output</li><li>HTTP only cookies</li><li>bind cookies to an IP:<ul><li>the attacker can use the stolen cookie only behind the same NAT/WebProxy as the victim</li></ul></li><li>always use absolute urls</li><li>url related:<ul><li>schemes: whitelist only http, https and ftp</li><li>domains:<ul><li>should contain only alphanum, &lsquo;-&rsquo; and &lsquo;.&rsquo;</li><li>should be followed only by &lsquo;?&rsquo;, &lsquo;/&rsquo;, &lsquo;#&rsquo; or end of string</li></ul></li><li>do not use credentials in urls: <code>user:pass@domain.com</code></li></ul></li></ul><h6 id=web-pen>web pen:</h6><ul><li>chars to use: &ldquo;&rsquo;/>&lt;)(][}{%</li></ul><h3 id=dom-xss-mitigations>DOM XSS mitigations:</h3><ul><li>do not use in js:<ul><li>document.URL</li><li>document.URLUnencoded</li><li>document.location (and many of its properties)</li><li>document.referrer</li><li>window.location (and many of its properties)</li><li>handle_of_window.location</li></ul></li></ul><h6 id=http-11-request-format>http 1.1 request format:</h6><ul><li>first line: {HTTP verb} {local_path} {protocol version information: HTTP/1.1}</li><li>next lines:<ul><li>key: value pairs that hold metadata</li><li>pairs:<ul><li>User-Agent(browser identification)</li><li>Host(domain name)</li><li>Accept(the MIME type to send the response as)</li><li>Accept-Language(the language to send the response as)</li><li>Referer(from which page is this begin accessed)</li><li>Content-Length(size in bytes of payload)</li></ul></li></ul></li><li>blank line</li><li>data the client wishes to send to the server</li></ul><h6 id=http-11-response-format>http 1.1 response format:</h6><ul><li>{protocol version information} {response code} {optional human readable response code}</li><li>response headers</li><li>blank line</li><li>response payload</li></ul><h6 id=http-attacks>http attacks:</h6><ul><li>header injection(response splitting ?!?!)</li></ul><h6 id=http-quirks>http quirks:</h6><ul><li>http/1.1:<ul><li>because http/1.1 must be compatible with http/0.9,
along with CRLF and LF, CR should also be stripped from a header</li><li>any header line that starts with a whitespace is considered a continuation of the previous line(multi-line headers)</li></ul></li></ul></article><nav class=site-nav><a href=https://www.dinudev.com//>Home</a>
<a href=https://www.dinudev.com//post/>All posts</a>
<a href=https://www.dinudev.com//journey/>The journey</a>
<a href=https://www.dinudev.com//paper/>Papers</a>
<a href=https://github.com/Owicca>GitHub</a></nav><footer class=site-footer><span class=owner>©2023 OWicca</span></footer></div><script src=https://www.dinudev.com/js/highlight.pack.js></script>
<script>hljs.initHighlightingOnLoad()</script></body></html>